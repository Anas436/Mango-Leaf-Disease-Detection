{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998d9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Images:\n",
      "Duplicate pair 1:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170706 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170706 (Custom).jpg\n",
      "\n",
      "Duplicate pair 2:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170708 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170708 (Custom).jpg\n",
      "\n",
      "Duplicate pair 3:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170709 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170709 (Custom).jpg\n",
      "\n",
      "Duplicate pair 4:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170712 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170712 (Custom).jpg\n",
      "\n",
      "Duplicate pair 5:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170714 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170714 (Custom).jpg\n",
      "\n",
      "Duplicate pair 6:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170717 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170717 (Custom).jpg\n",
      "\n",
      "Duplicate pair 7:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_171141 - Copy - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_171141 (Custom).jpg\n",
      "\n",
      "Duplicate pair 8:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140304 - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140304 (Custom).jpg\n",
      "\n",
      "Duplicate pair 9:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140539 - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140539 (Custom).jpg\n",
      "\n",
      "Duplicate pair 10:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140557 - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140557 (Custom).jpg\n",
      "\n",
      "Duplicate pair 11:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140624 - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140624 (Custom).jpg\n",
      "\n",
      "Duplicate pair 12:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153429 - Copy - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153429 (Custom).jpg\n",
      "\n",
      "Duplicate pair 13:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153557 - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153557 (Custom).jpg\n",
      "\n",
      "Duplicate pair 14:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153604 - Copy (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153604 (Custom).jpg\n",
      "\n",
      "Duplicate pair 15:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161600 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161600 (Custom)(1).jpg\n",
      "\n",
      "Duplicate pair 16:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161605 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161605 (Custom)(1).jpg\n",
      "\n",
      "Duplicate pair 17:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161611 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161611 (Custom)(1).jpg\n",
      "\n",
      "Duplicate pair 18:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161616 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161616 (Custom)(1).jpg\n",
      "\n",
      "Duplicate pair 19:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161620 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161620 (Custom)(1).jpg\n",
      "\n",
      "Duplicate pair 20:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161628 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161628 (Custom)(1).jpg\n",
      "\n",
      "Duplicate pair 21:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161631 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161631 (Custom)(1).jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "def get_file_hash(filename):\n",
    "    # Create a hash of the file's content\n",
    "    hasher = hashlib.md5()\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            data = f.read(65536)  # Read in 64k chunks\n",
    "            if not data:\n",
    "                break\n",
    "            hasher.update(data)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def find_duplicate_images(directory):\n",
    "    # Create a dictionary to store image hashes and their corresponding file paths\n",
    "    hash_dict = {}\n",
    "    duplicate_images = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is an image (you can add more image extensions as needed)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_hash = get_file_hash(file_path)\n",
    "\n",
    "                # If a file with the same hash is already in the dictionary, it's a duplicate\n",
    "                if file_hash in hash_dict:\n",
    "                    duplicate_images.append((file_path, hash_dict[file_hash]))\n",
    "                else:\n",
    "                    hash_dict[file_hash] = file_path\n",
    "\n",
    "    return duplicate_images\n",
    "\n",
    "# Specify the directory containing your image dataset\n",
    "image_directory = \"C:\\\\Users\\\\rawat\\\\Downloads\\\\MangoLeafBD Dataset\"\n",
    "\n",
    "duplicate_images = find_duplicate_images(image_directory)\n",
    "\n",
    "if duplicate_images:\n",
    "    print(\"Duplicate Images:\")\n",
    "    for index, (image1, image2) in enumerate(duplicate_images):\n",
    "        print(f\"Duplicate pair {index + 1}:\")\n",
    "        print(f\"Index 1: {image1}\")\n",
    "        print(f\"Index 2: {image2}\")\n",
    "        print()  # Add a newline for better readability\n",
    "else:\n",
    "    print(\"No duplicate images found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a0a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Images:\n",
      "Duplicate group 1:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170706 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170706 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 2:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170708 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170708 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 3:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170709 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170709 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 4:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170712 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170712 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 5:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170714 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170714 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 6:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170717 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170717 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 7:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_171141 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_171141 - Copy - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 8:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140304 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140304 - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 9:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140539 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140539 - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 10:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140557 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140557 - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 11:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140624 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140624 - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 12:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153429 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153429 - Copy - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 13:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153557 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153557 - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 14:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153604 (Custom).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153604 - Copy (Custom).jpg\n",
      "\n",
      "Duplicate group 15:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161600 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161600 (Custom).jpg\n",
      "\n",
      "Duplicate group 16:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161605 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161605 (Custom).jpg\n",
      "\n",
      "Duplicate group 17:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161611 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161611 (Custom).jpg\n",
      "\n",
      "Duplicate group 18:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161616 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161616 (Custom).jpg\n",
      "\n",
      "Duplicate group 19:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161620 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161620 (Custom).jpg\n",
      "\n",
      "Duplicate group 20:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161628 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161628 (Custom).jpg\n",
      "\n",
      "Duplicate group 21:\n",
      "Index 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161631 (Custom)(1).jpg\n",
      "Index 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161631 (Custom).jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_file_hash(filename):\n",
    "    # Create a hash of the file's content\n",
    "    hasher = hashlib.md5()\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            data = f.read(65536)  # Read in 64k chunks\n",
    "            if not data:\n",
    "                break\n",
    "            hasher.update(data)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def find_duplicate_images(directory):\n",
    "    # Create a dictionary to store image hashes and their corresponding file paths\n",
    "    hash_dict = defaultdict(list)\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is an image (you can add more image extensions as needed)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_hash = get_file_hash(file_path)\n",
    "\n",
    "                # Add the current file to the list of files with the same hash\n",
    "                hash_dict[file_hash].append(file_path)\n",
    "\n",
    "    # Filter out groups with only one image (not duplicates)\n",
    "    duplicate_groups = {k: v for k, v in hash_dict.items() if len(v) > 1}\n",
    "    \n",
    "    return duplicate_groups\n",
    "\n",
    "# Specify the directory containing your image dataset\n",
    "image_directory = \"C:\\\\Users\\\\rawat\\\\Downloads\\\\MangoLeafBD Dataset\"\n",
    "\n",
    "duplicate_groups = find_duplicate_images(image_directory)\n",
    "\n",
    "if duplicate_groups:\n",
    "    print(\"Duplicate Images:\")\n",
    "    for group_id, file_paths in enumerate(duplicate_groups.values(), 1):\n",
    "        print(f\"Duplicate group {group_id}:\")\n",
    "        for index, image_path in enumerate(file_paths, 1):\n",
    "            print(f\"Index {index}: {image_path}\")\n",
    "        print()  # Add a newline for better readability\n",
    "else:\n",
    "    print(\"No duplicate images found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceaeb4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Images:\n",
      "Removed duplicate image 1 in group 1: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170706 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 2: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170708 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 3: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170709 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 4: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170712 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 5: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170714 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 6: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_170717 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 7: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\20211011_171141 - Copy - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 8: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140304 - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 9: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140539 - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 10: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140557 - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 11: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_140624 - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 12: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153429 - Copy - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 13: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153557 - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 14: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Anthracnose\\IMG_20211011_153604 - Copy (Custom).jpg\n",
      "Removed duplicate image 1 in group 15: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161600 (Custom).jpg\n",
      "Removed duplicate image 1 in group 16: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161605 (Custom).jpg\n",
      "Removed duplicate image 1 in group 17: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161611 (Custom).jpg\n",
      "Removed duplicate image 1 in group 18: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161616 (Custom).jpg\n",
      "Removed duplicate image 1 in group 19: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161620 (Custom).jpg\n",
      "Removed duplicate image 1 in group 20: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161628 (Custom).jpg\n",
      "Removed duplicate image 1 in group 21: C:\\Users\\rawat\\Downloads\\MangoLeafBD Dataset\\Die Back\\20211129_161631 (Custom).jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_file_hash(filename):\n",
    "    # Create a hash of the file's content\n",
    "    hasher = hashlib.md5()\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            data = f.read(65536)  # Read in 64k chunks\n",
    "            if not data:\n",
    "                break\n",
    "            hasher.update(data)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def find_duplicate_images(directory):\n",
    "    # Create a dictionary to store image hashes and their corresponding file paths\n",
    "    hash_dict = defaultdict(list)\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is an image (you can add more image extensions as needed)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_hash = get_file_hash(file_path)\n",
    "\n",
    "                # Add the current file to the list of files with the same hash\n",
    "                hash_dict[file_hash].append(file_path)\n",
    "\n",
    "    # Filter out groups with only one image (not duplicates)\n",
    "    duplicate_groups = {k: v for k, v in hash_dict.items() if len(v) > 1}\n",
    "    \n",
    "    return duplicate_groups\n",
    "\n",
    "def remove_duplicate_images(duplicate_groups):\n",
    "    for group_id, file_paths in enumerate(duplicate_groups.values(), 1):\n",
    "        # Keep the first image in the group, delete the rest\n",
    "        for index, image_path in enumerate(file_paths[1:], 1):\n",
    "            if os.path.exists(image_path):\n",
    "                os.remove(image_path)\n",
    "                print(f\"Removed duplicate image {index} in group {group_id}: {image_path}\")\n",
    "            else:\n",
    "                print(f\"Image {index} in group {group_id} does not exist: {image_path}\")\n",
    "\n",
    "# Specify the directory containing your image dataset\n",
    "image_directory = \"C:\\\\Users\\\\rawat\\\\Downloads\\\\MangoLeafBD Dataset\"\n",
    "\n",
    "duplicate_groups = find_duplicate_images(image_directory)\n",
    "\n",
    "if duplicate_groups:\n",
    "    print(\"Duplicate Images:\")\n",
    "    remove_duplicate_images(duplicate_groups)\n",
    "else:\n",
    "    print(\"No duplicate images found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94582d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "main_folder_path = \"C:\\\\Users\\\\rawat\\\\Downloads\\\\MangoLeafBD Dataset\"\n",
    "\n",
    "# Create lists to store the loaded images and their labels\n",
    "image_list = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through subfolders (disease categories)\n",
    "for subfolder in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "    \n",
    "    # Check if 'subfolder' is a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        label = subfolder\n",
    "        \n",
    "        # Iterate through the files in the subfolder\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith('.jpg'):  # Adjust file extensions as needed\n",
    "                image_path = os.path.join(subfolder_path, filename)\n",
    "                \n",
    "                # Open and load the image\n",
    "                img = Image.open(image_path)\n",
    "                \n",
    "                # Append the loaded image to the list\n",
    "                image_list.append(img)\n",
    "                # Append the label to the labels list\n",
    "                labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e446ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3979"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e5ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum pixel value: 0\n",
      "Maximum pixel value: 227\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Minimum pixel value:\", np.min(image_list[0]))\n",
    "print(\"Maximum pixel value:\", np.max(image_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382720a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_width = 224\n",
    "target_height = 224\n",
    "\n",
    "resized_images = []\n",
    "\n",
    "for img in image_list:\n",
    "    # Resize the image to the target dimensions\n",
    "    img = img.resize((target_width, target_height))\n",
    "\n",
    "    resized_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d053ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a list to store the resized and normalized images\n",
    "resized_and_normalized_images = []\n",
    "\n",
    "for img in resized_images:\n",
    "\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Normalize pixel values\n",
    "    normalized_img = img_array / 227.0\n",
    "\n",
    "    resized_and_normalized_images.append(normalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd658c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoded = label_encoder.fit_transform(labels)\n",
    "print(label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083ce883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3979, 224, 224, 3)\n",
      "(3979,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(resized_and_normalized_images).shape)\n",
    "print(np.array(label_encoded).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db51921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacterial Canker    500\n",
       "Cutting Weevil      500\n",
       "Gall Midge          500\n",
       "Healthy             500\n",
       "Powdery Mildew      500\n",
       "Sooty Mould         500\n",
       "Die Back            493\n",
       "Anthracnose         486\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label_count=pd.DataFrame(labels).value_counts()\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e2bd39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an example image: (224, 224, 3)\n",
      "Minimum pixel value: 0.0\n",
      "Maximum pixel value: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of an example image:\", resized_and_normalized_images[0].shape)\n",
    "print(\"Minimum pixel value:\", np.min(resized_and_normalized_images[0]))\n",
    "print(\"Maximum pixel value:\", np.max(resized_and_normalized_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9858d862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.7092511  0.82378855 0.9339207 ]\n",
      "  [0.7092511  0.82378855 0.9339207 ]\n",
      "  [0.70484581 0.81938326 0.92951542]\n",
      "  ...\n",
      "  [0.69162996 0.77973568 0.89867841]\n",
      "  [0.70484581 0.77973568 0.9030837 ]\n",
      "  [0.7092511  0.7753304  0.9030837 ]]\n",
      "\n",
      " [[0.7092511  0.82378855 0.9339207 ]\n",
      "  [0.7092511  0.82378855 0.9339207 ]\n",
      "  [0.7092511  0.82378855 0.9339207 ]\n",
      "  ...\n",
      "  [0.69162996 0.77973568 0.89867841]\n",
      "  [0.69603524 0.78854626 0.90748899]\n",
      "  [0.69162996 0.78414097 0.9030837 ]]\n",
      "\n",
      " [[0.7092511  0.82378855 0.9339207 ]\n",
      "  [0.7092511  0.82378855 0.9339207 ]\n",
      "  [0.71365639 0.82819383 0.93832599]\n",
      "  ...\n",
      "  [0.68281938 0.78854626 0.9030837 ]\n",
      "  [0.68722467 0.80176211 0.91189427]\n",
      "  [0.6784141  0.79735683 0.90748899]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.83700441 0.92951542 1.02202643]\n",
      "  [0.83700441 0.92951542 1.02202643]\n",
      "  [0.83700441 0.92951542 1.02202643]\n",
      "  ...\n",
      "  [0.80176211 0.88546256 0.96035242]\n",
      "  [0.80176211 0.88546256 0.96035242]\n",
      "  [0.80176211 0.88546256 0.96035242]]\n",
      "\n",
      " [[0.83700441 0.92951542 1.02202643]\n",
      "  [0.83700441 0.92951542 1.02202643]\n",
      "  [0.83700441 0.92951542 1.02202643]\n",
      "  ...\n",
      "  [0.8061674  0.88986784 0.96475771]\n",
      "  [0.80176211 0.88546256 0.96035242]\n",
      "  [0.80176211 0.88546256 0.96035242]]\n",
      "\n",
      " [[0.83700441 0.92951542 1.02202643]\n",
      "  [0.83700441 0.92951542 1.02202643]\n",
      "  [0.83700441 0.92951542 1.02202643]\n",
      "  ...\n",
      "  [0.8061674  0.88986784 0.96475771]\n",
      "  [0.8061674  0.88986784 0.96475771]\n",
      "  [0.80176211 0.88546256 0.96035242]]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(resized_and_normalized_images[10])\n",
    "print(label_encoded[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87af85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "selected_images = []\n",
    "selected_labels = []\n",
    "\n",
    "# Create a dictionary to organize images by class\n",
    "class_images = {class_name: [] for class_name in set(label_encoded)}\n",
    "\n",
    "# Populate the dictionary with images and their corresponding labels\n",
    "for image, label in zip(image_list, label_encoded):\n",
    "    class_images[label].append(image)\n",
    "\n",
    "desired_per_class = 400\n",
    "\n",
    "# Loop through each class and select the desired number of images\n",
    "for class_name, image_list in class_images.items():\n",
    "    if len(image_list) >= desired_per_class:\n",
    "        selected_images.extend(random.sample(image_list, desired_per_class))\n",
    "        selected_labels.extend([class_name] * desired_per_class)\n",
    "    else:\n",
    "\n",
    "        selected_images.extend(image_list)\n",
    "        selected_labels.extend([class_name] * len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1648b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
